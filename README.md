<h1 align="center">ğŸ§¹ Data Preprocessing & Cleaning</h1>

<p align="center">
  <strong>A complete pipeline for cleaning, normalizing, and preparing raw text data</strong><br>
  Applied on the IMDB Movie Review Dataset â€“ ready for NLP & ML tasks.
</p>

<hr>

<h2>ğŸ“Œ Project Overview</h2>

<p>
This project demonstrates a <strong>comprehensive text preprocessing pipeline</strong> for Natural Language Processing (NLP).  
It cleans and transforms raw text into structured and meaningful data that can be used for Machine Learning models.
</p>

<ul>
  <li>ğŸ”¡ <strong>Lowercasing</strong>: Normalize text</li>
  <li>ğŸ·ï¸ <strong>HTML & URL Removal</strong>: Strip unwanted tags/links</li>
  <li>âœ‚ï¸ <strong>Punctuation & Emoji Handling</strong>: Clean noisy characters</li>
  <li>ğŸ’¬ <strong>Chat Slang Conversion</strong>: Expand abbreviations like LOL â†’ Laugh Out Loud</li>
  <li>ğŸ§  <strong>Spell Correction</strong>: Fix common typos</li>
  <li>ğŸ›‘ <strong>Stopwords Removal</strong>: Remove frequent but meaningless words</li>
  <li>ğŸ” <strong>Tokenization</strong>: Split into words/sentences</li>
  <li>ğŸŒ± <strong>Stemming & Lemmatization</strong>: Reduce words to root forms</li>
</ul>

<hr>

<h2>ğŸš€ Features</h2>

<ul>
  <li>ğŸ“‚ Loads and preprocesses the <code>IMDB 50K Movie Reviews</code> dataset</li>
  <li>âœ‚ï¸ Handles HTML tags, URLs, emojis, punctuation, and abbreviations</li>
  <li>ğŸ§¹ Provides functions for <strong>stopword removal, spell correction, chat slang handling</strong></li>
  <li>âš¡ Implements both <strong>stemming</strong> and <strong>lemmatization</strong></li>
  <li>âœ… Clean dataset ready for <strong>sentiment analysis, fake news detection, or ML models</strong></li>
</ul>

<hr>

<h2>ğŸ§  How It Works</h2>

<ol>
  <li>Load the IMDB Dataset</li>
  <li>Normalize text â†’ lowercase, remove HTML & URLs</li>
  <li>Clean text â†’ remove punctuation, emojis, stopwords</li>
  <li>Expand short forms (e.g., OMG â†’ Oh My God)</li>
  <li>Correct spelling errors using <code>TextBlob</code></li>
  <li>Tokenize text into sentences & words</li>
  <li>Apply stemming & lemmatization</li>
</ol>

<hr>

<h2>ğŸ“‚ Folder Structure</h2>

<pre>
data-preprocessing-cleaning/
â”œâ”€â”€ Data_Preprocessing_and_Cleaning.ipynb   â† Main Notebook
â”œâ”€â”€ IMDB Dataset.csv                        â† Raw Dataset
â””â”€â”€ README.md                               â† Project Documentation
</pre>

<hr>

<h2>âš™ï¸ Setup Instructions</h2>

<ol>
  <li>Clone the repository</li>
  
  <pre><code>git clone https://github.com/yourusername/data-preprocessing-cleaning</code></pre>

  <li>Install dependencies</li>

  <pre><code>pip install pandas textblob nltk emoji</code></pre>

  <li>Run the notebook in Google Colab or Jupyter</li>

  <pre><code>jupyter notebook Data_Preprocessing_and_Cleaning.ipynb</code></pre>
</ol>

<hr>

<h2>ğŸ§ª Sample Output</h2>

- Raw Input:  
  <code>"OMG!! Loved the movie ğŸ˜‚ğŸ˜‚. It was AMAZING!!! Visit http://movielink.com"</code>  

- After Preprocessing:  
  <code>"oh my god loved the movie it was amazing"</code>  

<hr>

<h2>ğŸ™Œ Credits</h2>

<p>
Created by <strong>Mehadi Hassan</strong> for text preprocessing and cleaning tasks in NLP pipelines.
</p>

<hr>

<p align="center">â­ Star this repo if you find it useful for your NLP/ML projects!</p>
